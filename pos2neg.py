from langchain_community.chat_models import ChatTongyi
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import PydanticOutputParser,StrOutputParser
from pydantic import BaseModel, Field
from dotenv import load_dotenv
load_dotenv()
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field
from typing import List
import os
import langchain

# langchain.debug = True
class AttributeChange(BaseModel):
    attribute: str = Field(..., description="Attribute type")
    origin: str = Field(..., description="Original value")
    target: str = Field(..., description="Replacement value")

class NegativeExample(BaseModel):
    sentence: str = Field(..., description="Generated negative sample sentences")
    attribute_change: List[AttributeChange] = Field(..., description="List of attribute changes in generated negative sample sentences")

class DataItem(BaseModel):
    image_name: str = Field(..., description="Image name")
    positive: str = Field(..., description="Positive example sentence")
    negatives: List[NegativeExample] = Field(..., description="List of NegativeExample")

class RawData(BaseModel):
    image_name: str = Field(..., description="Image name")
    positive: str = Field(..., description="Positive example sentence")
    negatives: List[str] = Field(..., description="List of generated negative sample sentences")
     
RAW_PROMPT_TEMPLATE = """

Replace the attribute words in the given sentence(positive) and Generate 10 replaced sentences(negatives).
Replacement must strictly follow these rules:
1.Only replace the specified attribute words (Material/Pattern/Transparency/Color). Do not modify any other parts of the sentence.
2.The replacement attribute word must be of the same type as the original. For example, if replacing a Material type attribute word, only use a Material attribute word.
3.The replacement attribute word must be selected from the provided Attribute Options list.
4.Replace 1 to 3 attribute words per sentence. Do not exceed 3 replacements.
5.Replacement priority:
    1.Prioritize replacing Material, Pattern, and Transparency.
    2.After the above three types are replaced, then replace Color.
6.The replacement target attribute word must be different from the original attribute word. 

Attribute Options:
Material: plastic, metal, glass, wooden, fabric, leather, stone, ceramic, paper, wool, rattan, velvet, crochet
Pattern: logo, striped, woven, checkered, studded, floral, perforated, dotted, plain
Transparency: transparent, translucent, opaque
Color: black, white, grey, blue, green, red, brown, pink, purple, yellow, orange;

eg:
(The following situations represent the generation of errors:
    positive: Two fluffy white puppies with soft fur rest on vibrant green grass near a beige wall.
    negative: Two fluffy white puppies with soft fur rest on vibrant green grass near a wool wall.
    attribute_change=[AttributeChange(attribute='Material', origin='beige', target='wool')]
 Because beige does not exist in Attribute Options.Violation of rule 3.)
(The following situations represent the generation of errors:
    positive: Two white pelicans with long, orange beaks rest on green grass against a backdrop of dark foliage.
    negative: Two white pelicans with long, orange beaks rest on plastic grass against a backdrop of dark foliage.
    attribute_change=[AttributeChange(attribute='Material', origin='green', target='plastic')]
 Becauese green is not belong to Material attribute words.Violation of rule 2.)
(The following situations represent the generation of errors:
    positive: A leopard with a spotted coat carries a dark brown prey across a rocky surface in a natural setting.
    negative: A leopard with a spotted coat carries a dark brown prey across a rocky surface in a natural setting.
    attribute_change=[]
 Because the sentence has no changes.Violation of rule 6.)

{format_struction}

image name:
{image_name}
input sentence:
{input}

"""


PROMPT_TEMPLATE = """
æˆ‘å°†æä¾›ä½ ä¸€ä¸ªæ ·æœ¬æ•°æ®,å…¶ä¸­åŒ…å«æ­£æ ·æœ¬æè¿°å’Œè´Ÿæ ·æœ¬æè¿°:
è¦æ±‚ï¼š
è¯·ä½ å‡†ç¡®æ‰¾å‡ºæ­£æ ·æœ¬åˆ°è´Ÿæ ·æœ¬ä¸­çš„å±æ€§çš„å˜æ¢ï¼Œå°†å˜åŒ–çš„å±æ€§åˆ†ç±»(Material/Pattern/Transparency/Color)ä½¿ç”¨attributeè®°å½•ï¼Œå¹¶å°†æ­£ç¡®çš„è¯originå’Œå˜åŒ–åçš„è¯targetè®°å½•ã€‚

å±æ€§è¯çš„ç±»åˆ«è¯·ä»ä¸‹é¢ç»™å‡ºçš„ç±»åˆ«ä¸­å»æ‰¾ï¼Œä¾‹å¦‚stripedå±äºPatternç±»:
Material: plastic, metal, glass, wooden, fabric, leather, stone, ceramic, paper, wool, rattan, velvet, crochet
Pattern: logo, striped, woven, checkered, studded, floral, perforated, dotted, plain
Transparency: transparent, translucent, opaque
Color: black, white, grey, blue, green, red, brown, pink, purple, yellow, orange;

{format_struction}

æ ·æœ¬æ•°æ®ï¼š
{input}
"""




def get_chain():
    #é¢„ç”Ÿæˆè´Ÿæ ·æœ¬
    raw_llm = ChatTongyi(
        model="qwen-flash",
        model_kwargs={"temperature": 0.1,"enable_thinking": True  }
        )

    raw_parser =  PydanticOutputParser(pydantic_object=RawData)
    raw_prompt = PromptTemplate(
        input_variables=["input","image_name"],
        template=RAW_PROMPT_TEMPLATE,
        partial_variables={"format_struction": raw_parser.get_format_instructions()}
    )

    #å¤„ç†ç”Ÿæˆçš„è´Ÿæ ·æœ¬
    llm = ChatTongyi(
        model="qwen-flash",
        model_kwargs={"temperature": 0.1,"enable_thinking": False  }
        )
    parser =  PydanticOutputParser(pydantic_object=DataItem)
    prompt = PromptTemplate(
        input_variables=["input"],
        template=PROMPT_TEMPLATE,
        partial_variables={"format_struction": parser.get_format_instructions()}
    )
    chain = raw_prompt | raw_llm | raw_parser  | prompt | llm | parser
    return chain


import json

def batch_read_jsonl(file_path, batch_size=10):
    """
    æ‰¹æ¬¡è¯»å–JSON Linesæ–‡ä»¶
    :param file_path: æ–‡ä»¶è·¯å¾„
    :param batch_size: æ¯æ‰¹è¯»å–çš„è¡Œæ•°
    :return: ç”Ÿæˆå™¨ï¼Œæ¯æ¬¡è¿”å›ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼ˆåˆ—è¡¨ï¼‰
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        batch = []  # å­˜å‚¨å½“å‰æ‰¹æ¬¡çš„æ•°æ®
        for line in f:
            line = line.strip()
            if not line:
                continue  # è·³è¿‡ç©ºè¡Œ
            try:
                data = json.loads(line)
                batch.append(data)
                # å½“æ‰¹æ¬¡å¤§å°è¾¾åˆ°è®¾å®šå€¼æ—¶ï¼Œè¿”å›è¯¥æ‰¹æ¬¡å¹¶æ¸…ç©º
                if len(batch) >= batch_size:
                    yield batch
                    batch = []
            except json.JSONDecodeError:
                print(f"è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ: {line}")
        # å¤„ç†æœ€åä¸€æ‰¹ï¼ˆå¯èƒ½ä¸è¶³batch_sizeï¼‰
        if batch:
            yield batch


def get_processed_image_names(output_file):
    """è¯»å–å·²å¤„ç†çš„ç»“æœæ–‡ä»¶ï¼Œè¿”å›å·²å¤„ç†è¿‡çš„ image_name é›†åˆ"""
    if not os.path.exists(output_file):
        return set()
    processed = set()
    with open(output_file, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line.strip())
                processed.add(data.get("image_name"))
            except:
                continue
    return processed


if __name__ == "__main__":
    chain = get_chain()
    output_file = "processed_results.jsonl"
    processed_images = get_processed_image_names(output_file)
    print(f"âœ… å·²æ£€æµ‹åˆ° {len(processed_images)} ä¸ªå·²å¤„ç†æ ·æœ¬ï¼Œå°†è‡ªåŠ¨è·³è¿‡ã€‚")

    # è‡ªåŠ¨è®°å½•æ–­ç‚¹æ–‡ä»¶
    checkpoint_file = "resume_checkpoint.txt"
    start_batch = 0
    if os.path.exists(checkpoint_file):
        with open(checkpoint_file, "r") as f:
            start_batch = int(f.read().strip() or 0)
        print(f"ğŸ”„ ä»ç¬¬ {start_batch+1} æ‰¹æ¬¡ç»§ç»­å¤„ç†ã€‚")

    with open(output_file, 'a', encoding='utf-8') as f_out:
        for i, batch in enumerate(batch_read_jsonl('./cleaned_image_descriptions.jsonl', batch_size=20)):
            if i < start_batch:
                continue  # è·³è¿‡å·²å¤„ç†æ‰¹æ¬¡

            print(f"\n===== ç¬¬{i+1}æ‰¹æ•°æ® =====")

            # è¿‡æ»¤æ‰å·²ç»å¤„ç†è¿‡çš„æ ·æœ¬
            batch = [item for item in batch if item["image_name"] not in processed_images]
            if not batch:
                print(f"ç¬¬{i+1}æ‰¹å…¨éƒ¨å·²å¤„ç†ï¼Œè·³è¿‡ã€‚")
                continue

            inputs = [{"input": item["description"], "image_name": item["image_name"]} for item in batch]

            try:
                outputs = chain.batch(inputs)
                for result in outputs:
                    result_dict = result.model_dump()
                    f_out.write(json.dumps(result_dict, ensure_ascii=False) + '\n')
                    processed_images.add(result_dict["image_name"])
                f_out.flush()
                print(f"âœ… ç¬¬{i+1}æ‰¹å¤„ç†å®Œæˆã€‚")

                # å†™å…¥æ–­ç‚¹
                with open(checkpoint_file, "w") as f_ckpt:
                    f_ckpt.write(str(i))

            except Exception as e:
                print(f"âŒ ç¬¬{i+1}æ‰¹å¤„ç†å‡ºé”™ï¼š{str(e)}")
                print("ç¨‹åºå°†åœ¨ä¸‹æ¬¡å¯åŠ¨æ—¶ä»è¯¥æ‰¹æ¬¡ç»§ç»­ã€‚")
                break

    print(f"ğŸ æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {output_file}")
